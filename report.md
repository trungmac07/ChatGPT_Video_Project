# **BÃ¡o cÃ¡o Ä‘á»“ Ã¡n Video**

## **ThÃ nh ViÃªn**

|MSSV|Há» TÃªn|
|----|------|
|21127367 | Äá»— Tháº¿ NghÄ©a|
|21127384 | DÆ°Æ¡ng Háº¡nh Nhi|
|21127403 | Nguyá»…n Minh QuÃ¢n|
|21127461 | LÃª ThÃ nh Trung|
|21127462 | Máº¡c Tuáº¥n Trung|

## **MÃ´ HÃ¬nh NgÃ´n Ngá»¯**

MÃ´ hÃ¬nh ngÃ´n ngá»¯ lÃ  mÃ´ hÃ¬nh xÃ¡c suáº¥t cá»§a ngÃ´n ngá»¯ tá»± nhiÃªn. ÄÃ¢y lÃ  má»™t mÃ´ hÃ¬nh trÃ­ tuá»‡ nhÃ¢n táº¡o hoÃ n thÃ nh má»™t cÃ¢u báº±ng cÃ¡ch dá»± Ä‘oÃ¡n tá»« tiáº¿p theo sáº½ xuáº¥t hiá»‡n sau cÃ¡c tá»« Ä‘Ã£ cÃ³ trÆ°á»›c. 


MÃ´ hÃ¬nh ngÃ´n ngá»¯ há»c tá»« sá»± phÃ¢n bá»‘ xÃ¡c suáº¥t trÃªn cÃ¡c tá»« hoáº·c chuá»—i tá»«. Trong thá»±c táº¿, nÃ³ Ä‘Æ°a ra xÃ¡c suáº¥t Ä‘á»ƒ má»™t chuá»—i tá»« nháº¥t Ä‘á»‹nh lÃ  â€œhá»£p lá»‡â€. Sá»± há»£p lá»‡ nÃ y khÃ´ng Ä‘á» cáº­p Ä‘áº¿n giÃ¡ trá»‹ ngá»¯ phÃ¡p mÃ  thay vÃ o Ä‘Ã³, cÃ¢u há»£p lá»‡ sá»‘ giá»‘ng vá»›i cÃ¡ch má»i ngÆ°á»i viáº¿t, Ä‘Ã³ lÃ  nhá»¯ng gÃ¬ mÃ´ hÃ¬nh ngÃ´n ngá»¯ há»c Ä‘Æ°á»£c.

Giáº£ sá»­ chÃºng ta cÃ³ má»™t cÃ¢u chÆ°a hoÃ n chá»‰nh sau:

<center><b>HÃ´m nay tÃ´i ...</b></center>

Tá»« nhá»¯ng tá»« trÆ°á»›c Ä‘Ã³ vÃ  dá»±a trÃªn nhá»¯ng gÃ¬ mÃ  mÃ´ hÃ¬nh há»c Ä‘Æ°á»£c trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n, mÃ´ hÃ¬nh cÃ³ thá»ƒ sáº½ dá»± Ä‘oÃ¡n tá»« tiáº¿p theo trong cÃ¢u nÃ y. Má»™t sá»‘ vÃ­ dá»¥ nhÆ°:

<center><b>HÃ´m nay tÃ´i<span style="color:red"> há»c</span></b></center>

<center><b>HÃ´m nay tÃ´i<span style="color:red"> Ä‘i</span></b></center>

<center><b>HÃ´m nay tÃ´i<span style="color:red"> lÃ m</span></b></center>

Thá»±c táº¿ cÃ³ 2 loáº¡i mÃ´ hÃ¬nh ngÃ´n ngá»¯ phá»• biáº¿n

### **MÃ´ hÃ¬nh ngÃ´n ngá»¯ dá»±a trÃªn xÃ¡c suáº¥t thá»‘ng kÃª**

MÃ´ hÃ¬nh ngÃ´n ngá»¯ thá»‘ng kÃª há»c xÃ¡c suáº¥t xuáº¥t hiá»‡n cá»§a tá»« dá»±a trÃªn cÃ¡c vÃ­ dá»¥ vá» vÄƒn báº£n. Dá»±a trÃªn nhá»¯ng thá»‘ng kÃª vÃ  táº§n suáº¥t xuáº¥t hiá»‡n cá»§a cÃ¡c tá»«, mÃ´ hÃ¬nh ngÃ´n ngá»¯ dá»±a trÃªn xÃ¡c suáº¥t sáº½ dá»± Ä‘oÃ¡n tá»« tiáº¿p theo trong cÃ¢u dá»±a trÃªn nhá»¯ng tá»« trÆ°á»›c Ä‘Ã³ trong cÃ¢u.

#### **MÃ´ hÃ¬nh ngÃ´n ngá»¯ Unigram**

MÃ´ hÃ¬nh ngÃ´n ngá»¯ Unigram lÃ  má»™t trong nhá»¯ng mÃ´ hÃ¬nh Ä‘Æ¡n giáº£n trong lÄ©nh vá»±c xá»­ lÃ½ ngÃ´n ngá»¯ tá»± nhiÃªn (NLP). ÄÆ°á»£c sá»­ dá»¥ng Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ vÃ  mÃ´ táº£ xÃ¡c suáº¥t xuáº¥t hiá»‡n cá»§a má»—i tá»« Ä‘Æ¡n trong má»™t ngÃ´n ngá»¯, mÃ´ hÃ¬nh Unigram giÃºp hiá»ƒu ráº¥t tá»‘t vá» cáº¥u trÃºc ngÃ´n ngá»¯ vÃ  sá»± phá»¥ thuá»™c giá»¯a cÃ¡c tá»«.

Giáº£ sá»­ ta cÃ³ má»™t cÃ¢u cáº¥u thÃ nh tá»« cÃ¡c tá»«:
$$t_1,t_2,t_3,...t_n$$

XÃ¡c suáº¥t cá»§a cÃ¢u nÃ y sáº½ lÃ :
$$P(t_1,t_2,t_3,â€¦,t_ğ‘› )=P(t_1 )  P(t_2 )  P(t_3 )â€¦P(t_n)$$


Má»™t vÃ­ dá»¥ thá»±c táº¿ nhÆ° sau:
<center>HÃ´m nay lÃ  má»™t ngÃ y Ä‘áº¹p trá»i báº¡n muá»‘n Ä‘i dÃ£ ngoáº¡i hay báº¡n muá»‘n á»Ÿ nhÃ ?</center>

Má»™t vÃ i dÃ²ng code Python sau Ä‘Ã¢y sáº½ giÃºp vÃ­ dá»¥ dá»… hiá»ƒu hÆ¡n

Äáº§u tiÃªn ta chuáº©n bá»‹ Ä‘oáº¡n dá»¯ liá»‡u trÃªn


```python
# Dá»¯ liá»‡u vÄƒn báº£n
text = "HÃ´m nay lÃ  má»™t ngÃ y Ä‘áº¹p trá»i báº¡n muá»‘n Ä‘i dÃ£ ngoáº¡i hay báº¡n muá»‘n á»Ÿ nhÃ ?"

# Chuyá»ƒn Ä‘á»•i thÃ nh danh sÃ¡ch cÃ¡c tá»«
words = text.split()
```

BÆ°á»›c tÃ­nh xÃ¡c suáº¥t


```python
# TÃ­nh xÃ¡c suáº¥t cho má»—i tá»« sá»­ dá»¥ng mÃ´ hÃ¬nh Unigram
unigram_probabilities = {}
total_words = len(words)

for word in set(words):
    word_count = words.count(word)
    probability = word_count / total_words
    unigram_probabilities[word] = probability

# In káº¿t quáº£
print("XÃ¡c suáº¥t cá»§a cÃ¡c tá»«: ")
for key,value in unigram_probabilities.items():
    print(key,":",value)
```

    XÃ¡c suáº¥t cá»§a cÃ¡c tá»«: 
    trá»i : 0.058823529411764705
    lÃ  : 0.058823529411764705
    nhÃ ? : 0.058823529411764705
    ngÃ y : 0.058823529411764705
    má»™t : 0.058823529411764705
    Ä‘áº¹p : 0.058823529411764705
    báº¡n : 0.11764705882352941
    hay : 0.058823529411764705
    nay : 0.058823529411764705
    Ä‘i : 0.058823529411764705
    dÃ£ : 0.058823529411764705
    á»Ÿ : 0.058823529411764705
    muá»‘n : 0.11764705882352941
    HÃ´m : 0.058823529411764705
    ngoáº¡i : 0.058823529411764705
    

Vá»›i ráº¥t nhiá»u vÄƒn báº£n dá»¯ liá»‡u cÃ³ thá»ƒ Ä‘Æ°á»£c mÃ´ táº£ thÃ nh báº£ng nhÆ° sau:

|Tá»« |VÄƒn báº£n 1| VÄƒn báº£n 2|...|
|---|---------|----------|---|
|TÃ´i| 0.051   |0.039     |...|
|LÃ  | 0.031   |0.011     |...|
|Anh| 0.012   |0.007     |...|
|Äi | 0.001   |0.002     |...|

#### **MÃ´ hÃ¬nh ngÃ´n ngá»¯ Bigram**

Dá»±a trÃªn cÃ¡ch tiáº¿p cáº­n tÆ°Æ¡ng tá»± nhÆ° Unigram, mÃ´ hÃ¬nh ngÃ´n ngá»¯ Bigram Ä‘Æ°á»£c má»Ÿ rá»™ng Ã½ tÆ°á»Ÿng tá»« mÃ´ hÃ¬nh Unigram báº±ng cÃ¡ch thay vÃ¬ tÃ­nh xÃ¡c suáº¥t cÃ¡c tá»« riÃªng láº», Bigram sáº½ xem xÃ©t sá»± phá»¥ thuá»™c giá»¯a cÃ¡c tá»« theo cáº·p liÃªn tiáº¿p. 

Trong mÃ´ hÃ¬nh Bigram, giáº£ Ä‘á»‹nh ráº±ng xÃ¡c suáº¥t xuáº¥t hiá»‡n cá»§a má»™t tá»« phá»¥ thuá»™c vÃ o tá»« liá»n trÆ°á»›c nÃ³. Äiá»u nÃ y giÃºp mÃ´ hÃ¬nh hiá»ƒu Ä‘Æ°á»£c má»‘i quan há»‡ giá»¯a cÃ¡c tá»« theo cáº·p liÃªn tiáº¿p, tÄƒng cÆ°á»ng kháº£ nÄƒng dá»± Ä‘oÃ¡n tá»« tiáº¿p theo trong má»™t chuá»—i vÄƒn báº£n.

Giáº£ sá»­ ta cÃ³ má»™t cÃ¢u cáº¥u thÃ nh tá»« cÃ¡c tá»«:
$$t_1,t_2,t_3,...t_n$$

XÃ¡c suáº¥t cá»§a cÃ¢u nÃ y sáº½ lÃ :
$$P(t_1,t_2,t_3,â€¦,t_ğ‘› )=P(t_1 )  P(t_2|t_1 )  P(t_3|t_2 )â€¦P(t_n|t_{n-1})$$

Tiáº¿p tá»¥c vá»›i cÃ¢u vÃ­ dá»¥ trÃªn

<center>HÃ´m nay lÃ  má»™t ngÃ y Ä‘áº¹p trá»i báº¡n muá»‘n Ä‘i dÃ£ ngoáº¡i hay báº¡n muá»‘n á»Ÿ nhÃ ?</center>

Ta láº­p báº£ng cho mÃ´ hÃ¬nh Bigram nhÆ° sau:

|       |HÃ´m|nay|lÃ |má»™t|ngÃ y|Ä‘áº¹p|trá»i|báº¡n|muá»‘n|Ä‘i|dÃ£|ngoáº¡i|hay |á»Ÿ |nhÃ ?|
|-------|---|---|--|---|----|---|----|---|----|--|--|-----|---|--|----|
|<b> HÃ´m  </b>  | 0 | 0 | 0| 0 | 0  | 0 | 0  | 0 | 0  |0 | 0| 0   | 0 | 0| 0  |
|<b> nay  </b> | 1 | 0 | 0| 0 | 0  | 0 | 0  | 0 | 0  |0 | 0| 0   | 0 | 0| 0  |
|<b> lÃ    </b> | 0 | 1 | 0| 0 | 0  | 0 | 0  | 0 | 0  |0 | 0| 0   | 0 | 0| 0  |
|<b> má»™t  </b> | 0 | 0 |1 | 0 | 0  | 0 | 0  | 0 | 0  |0 | 0| 0   | 0 | 0| 0  |
|<b> ngÃ y </b> | 0 | 0 | 0| 1 | 0  | 0 | 0  | 0 | 0  |0 | 0| 0   | 0 | 0| 0  |
|<b> Ä‘áº¹p  </b> | 0 | 0 | 0| 0 | 1  | 0 | 0  | 0 | 0  |0 | 0| 0   | 0 | 0| 0  |
|<b> trá»i </b> | 0 | 0 | 0| 0 | 0  |1  | 0  | 0 | 0  |0 | 0| 0   | 0 | 0| 0  |
|<b> báº¡n  </b> | 0 | 0 | 0| 0 | 0  | 0 | 1  | 0 | 0  |0 | 0| 0   | 0 | 0| 0  |
|<b> muá»‘n </b> | 0 | 0 | 0| 0 | 0  | 0 | 0  | 1 | 0  |0 | 0| 0   | 0 | 0| 0  |
|<b> Ä‘i   </b> | 0 | 0 | 0| 0 | 0  | 0 | 0  | 0 |0.5 |0 | 0| 0   | 0 | 0| 0  |
|<b> dÃ£   </b> | 0 | 0 | 0| 0 | 0  | 0 | 0  | 0 | 0  |1 | 0| 0   | 0 | 0| 0  |
|<b> ngoáº¡i</b> | 0 | 0 | 0| 0 | 0  | 0 | 0  | 0 | 0  |0 |1 | 0   | 0 | 0| 0  |
|<b> hay  </b> | 0 | 0 | 0| 0 | 0  | 0 | 0  | 0 | 0  |0 | 0| 1   | 0 | 0| 0  |
|<b> á»Ÿ    </b> | 0 | 0 | 0| 0 | 0  | 0 | 0  | 0 |0.5 |0 | 0| 0   | 0 | 0| 0  |
|<b> nhÃ ? </b> | 0 | 0 | 0| 0 | 0  | 0 | 0  | 0 | 0  |0 | 0| 0   | 0 | 1| 0  |

#### **MÃ´ hÃ¬nh ngÃ´n ngá»¯ N-grams**

Vá»›i Unigram lÃ  xÃ¡c suáº¥t cÃ¡c tá»« Ä‘Æ¡n láº»
Vá»›i Bigram lÃ  xÃ¡c suáº¥t cÃ¡c cáº·p tá»« xuáº¥t hiá»‡n
CÃ²n vá»›i N-grams, Ä‘Ã¢y lÃ  má»™t phÆ°Æ¡ng phÃ¡p thá»‘ng kÃª sá»­ dá»¥ng trong xá»­ lÃ½ ngÃ´n ngá»¯ Ä‘á»ƒ mÃ´ táº£ xÃ¡c suáº¥t xuáº¥t hiá»‡n cá»§a má»™t chuá»—i cÃ¡c tá»« (nhiá»u tá»« vá»›i N lÃ  sá»‘ tá»« trong má»™t chuá»—i) dá»±a trÃªn má»™t lá»‹ch sá»­ cá»¥ thá»ƒ cá»§a cÃ¡c tá»« trÆ°á»›c Ä‘Ã³ (thÆ°á»ng Ä‘Æ°á»£c há»c tá»« cÃ¡c vÄƒn báº£n cÃ³ sáºµn).

Trong N-grams, "N" thÆ°á»ng Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ chá»‰ sá»‘ lÆ°á»£ng cÃ¡c tá»« Ä‘Æ°á»£c xem xÃ©t cÃ¹ng má»™t lÃºc. VÃ­ dá»¥:

Trong mÃ´ hÃ¬nh bigram (N=2), xÃ¡c suáº¥t xuáº¥t hiá»‡n cá»§a tá»«ng tá»« phá»¥ thuá»™c vÃ o tá»« trÆ°á»›c nÃ³.\
Trong mÃ´ hÃ¬nh trigram (N=3), xÃ¡c suáº¥t xuáº¥t hiá»‡n cá»§a tá»«ng tá»« phá»¥ thuá»™c vÃ o cáº£ hai tá»« trÆ°á»›c nÃ³.

Giáº£ sá»­ ta cÃ³ má»™t cÃ¢u cáº¥u thÃ nh tá»« cÃ¡c tá»«:
$$t_1,t_2,t_3,...t_n$$

LÃºc nÃ y MÃ´ hÃ¬nh N-grams táº­p trung vÃ o xÃ¡c suáº¥t Ä‘iá»u kiá»‡n cá»§a má»™t tá»« dá»±a trÃªn N-1 tá»« trÆ°á»›c Ä‘Ã³. Äiá»u nÃ y Ä‘Æ°á»£c biá»ƒu diá»…n báº±ng cÃ´ng thá»©c:
$$P(t_n|t_1,t_2,...,t_{n-1})$$

### **MÃ´ hÃ¬nh ngÃ´n ngá»¯ dá»±a trÃªn máº¡ng nÆ¡ ron**

#### **Váº¥n Ä‘á» á»Ÿ mÃ´ hÃ¬nh ngÃ´n ngá»¯ xÃ¡c suáº¥t**

Giáº£ sá»­ cÃ¢u sau:

<center> TÃ´i nghÄ© lÃ  chÃº chÃ³ Äƒn xong bá»¯a Äƒn rá»“i </center>

Vá»›i mÃ´ hÃ¬nh xÃ¡c suáº¥t ta cÃ³ 
$$P(\text{Äƒn}|\text{chÃº chÃ³})$$
Äiá»u nÃ y sáº½ giÃºp mÃ´ hÃ¬nh dá»± Ä‘oÃ¡n Ä‘Æ°á»£c tá»« "Äƒn" sau "chÃº chÃ³"

Tuy nhiÃªn náº¿u ta thay Ä‘á»•i "chÃº chÃ³" thÃ nh "chÃº mÃ¨o". 
<center>TÃ´i nghÄ© lÃ  chÃº mÃ¨o Äƒn xong bá»¯a Äƒn rá»“i</center>

Äiá»u nÃ y gÃ¢y khÃ³ khÄƒn cho mÃ´ hÃ¬nh ngÃ´n ngá»¯ dá»±a trÃªn xÃ¡c suáº¥t bá»Ÿi vÃ¬ trong dá»¯ liá»‡u há»c náº¿u nhÆ° thiáº¿u Ä‘i cá»¥m "chÃº mÃ¨o Äƒn" Ä‘á»“ng nghÄ©a vá»›i viá»‡c

$$P(\text{Äƒn}|\text{chÃº mÃ¨o}) = 0$$

MÃ´ hÃ¬nh sáº½ khÃ´ng thá»ƒ nÃ o dá»± Ä‘oÃ¡n Ä‘Æ°á»£c tá»« "Äƒn" náº¿u trÆ°á»›c Ä‘Ã³ lÃ  "chÃº mÃ¨o"

#### **Words Embedding**

Vá»›i ká»¹ thuáº­t nhÃºng (embedding), tá»©c lÃ  chuyá»ƒn cÃ¡c tá»« vá» dáº¡ng vector Ä‘áº·c trÆ°ng tÆ°Æ¡ng á»©ng vá»›i tá»« Ä‘Ã³, ta sáº½ nháº­n Ä‘Æ°á»£c 2 vector Ä‘áº·c trÆ°ng tá»« 2 tá»« khÃ¡c nhau lÃ  "chÃ³" vÃ  "mÃ¨o"

VÃ  vá»›i mÃ´ hÃ¬nh máº¡ng nÆ¡ ron sáº½ tÃ¬m tháº¥y Ä‘iá»ƒm tÆ°Æ¡ng Ä‘á»“ng giá»¯a 2 vector Ä‘áº·c trÆ°ng nÃ y. Äiá»u nÃ y giÃºp Ã­ch ráº¥t nhiá»u cho mÃ´ hÃ¬nh ngÃ´n ngá»¯ cá»§a chÃºng ta dá»± Ä‘oÃ¡n chÃ­nh xÃ¡c tá»« "Äƒn" dÃ¹ cho "chÃº mÃ¨o Äƒn" xuáº¥t hiá»‡n Ã­t hoáº·c chÆ°a tá»«ng xuáº¥t hiá»‡n trong bá»™ dá»¯ liá»‡u huáº¥n luyá»‡n

<center><image src="https://i.imgur.com/bLvLuTq.png" height=50% width=50%}/></center>

#### **CÃ¡ch hoáº¡t Ä‘á»™ng**

<center><image alt="SÆ¡ Ä‘á»“ mÃ´ hÃ¬nh ngÃ´n ngá»¯ máº¡ng nÆ¡ rÆ¡n Ä‘Æ¡n giáº£n" src="https://i.imgur.com/iqE2JgN.png" width = 50% height=50%/></center>

**Lá»›p Ä‘áº§u vÃ o (Input layer)**

Ta sáº½ cÃ³ má»™t tá»« Ä‘iá»ƒn lÃ  má»™t táº­p há»£p chá»©a toÃ n bá»™ cÃ¡c tá»« mÃ  mÃ´ hÃ¬nh Ä‘Ã£ há»c Ä‘Æ°á»£c. á» Ä‘Ã¢y ta kÃ½ hiá»‡u nÃ³ lÃ  $V$\
Dá»±a trÃªn loáº¡i mÃ´ hÃ¬nh ta sáº½ cÃ³ má»™t cá»­a sá»• trÆ°á»£t trÃªn $N$ tá»« Ä‘Ã£ Ä‘Æ°á»£c táº¡o ra trÆ°á»›c Ä‘Ã³ Ä‘á»ƒ xÃ¡c Ä‘á»‹nh xÃ¡c suáº¥t cho tá»« tiáº¿p theo.\
Vá»›i má»—i tá»« Ä‘Æ°á»£c chá»n nhÆ° váº­y, ta sáº½ táº¡o má»™t one-hot vector (vector chá»‰ toÃ n 0 vÃ  chá»‰ báº±ng 1 táº¡i vá»‹ trÃ­ cá»§a tá»« Ä‘Ã³ trong tá»« Ä‘iá»ƒn $V$)\
VÃ­ dá»¥ vá»›i tá»« "Äƒn" náº±m á»Ÿ vá»‹ trÃ­ thá»© 97 trong tá»« Ä‘iá»ƒn $V$ vÃ  $x$ lÃ  one-hot vector cá»§a "Äƒn":
$$ x = \begin{bmatrix}
x_1 \\
x_2 \\
... \\
x_{|V|}
\end{bmatrix}\\ $$

$$x_{97} = 1 \>\> \text{vÃ } \>\> x_i = 0 \>\>\>\> \forall i \neq 97$$


**Lá»›p nhÃºng (Embedding layer)**

ÄÃ¢y lÃ  lá»›p thá»±c hiá»‡n chá»©c nÄƒng chuyá»ƒn Ä‘á»•i má»™t tá»« thÃ nh má»™t vector Ä‘áº·c trÆ°ng cá»§a chÃºng.\
Táº¡i Ä‘Ã¢y, má»™t ma tráº­n mÃ£ hÃ³a $E$ cÃ³ kÃ­ch thÆ°á»›c $n \times |V|$ sáº½ Ä‘Æ°á»£c nhÃ¢n vá»›i cÃ¡c one-hot vector Ä‘Æ°á»£c xÃ¢y dá»±ng tá»« lá»›p Ä‘áº§u vÃ o.\
Do one-hot vector lÃ  má»™t vector toÃ n 0 vÃ  chá»‰ báº±ng 1 táº¡i vá»‹ trÃ­ tá»« Ä‘Ã³ xuáº¥t hiá»‡n trong tá»« Ä‘iá»ƒn, phÃ©p nhÃ¢n ma tráº­n trÃªn Ä‘á»“ng nghÄ©a vá»›i viá»‡c ta rÃºt trÃ­ch ra cá»™t tÆ°Æ¡ng á»©ng chá»©a vector mÃ£ hÃ³a cho tá»« 
<center><image src="https://i.imgur.com/3u3jvKt.png" width=50% height=50%/></center>

**CÃ¡c lá»›p áº©n (Hidden layers)**

MÃ´ hÃ¬nh ngÃ´n ngá»¯ dá»±a trÃªn máº¡ng nÆ¡-ron thÆ°á»ng cÃ³ cáº¥u trÃºc vá»›i nhiá»u hidden layer. Hidden layer Ä‘Ã³ng má»™t vai trÃ² quan trá»ng trong quÃ¡ trÃ¬nh há»c vÃ  hiá»ƒu ngÃ´n ngá»¯. CÃ³ thá»ƒ nÃ³i cÃ¡c máº¡ng nÆ¡ ron áº©n nÃ y lÃ  thÃ nh pháº§n chÃ­nh Ä‘á»ƒ mÃ´ hÃ¬nh thá»±c hiá»‡n xÃ¡c Ä‘á»‹nh trá»ng sá»‘ cho cÃ¡c tá»« cÃ³ thá»ƒ xuáº¥t hiá»‡n tiáº¿p theo.\
Trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n cÃ¡c lá»›p nÃ y Ä‘Ã£ Ä‘Æ°á»£c há»c cÃ¡c Ä‘áº·c trÆ°ng ngÃ´n ngá»¯ áº©n. CÃ¡c trá»ng sá»‘ cá»§a hidden layer Ä‘Æ°á»£c Ä‘iá»u chá»‰nh thÃ´ng qua quÃ¡ trÃ¬nh lan truyá»n ngÆ°á»£c (backpropagation) Ä‘á»ƒ cá»±c tiá»ƒu hÃ³a sai sá»‘ giá»¯a dá»± Ä‘oÃ¡n vÃ  thá»±c táº¿.\

Máº¡ng nÆ¡ ron áº©n giÃºp mÃ´ hÃ¬nh há»c vÃ  hiá»ƒu ngá»¯ cáº£nh, táº¡o ra dá»± Ä‘oÃ¡n tá»« tiáº¿p theo cÃ³ Ã½ nghÄ©a chá»© khÃ´ng cÃ²n lÃ  cÃ¡c cÃ¢u vÃ´ nghÄ©a láº¯p ghÃ©p tá»« nhá»¯ng tá»« xuáº¥t hiá»‡n vá»›i táº¥n suÃ¢t lá»›n. 
Máº¡ng nÆ¡-ron cÃ³ thá»ƒ há»c cÃ¡c biá»ƒu diá»…n phá»©c táº¡p cá»§a ngÃ´n ngá»¯.
CÃ ng nhiá»u tham sá»‘ cho cÃ¡c hidden layer, mÃ´ hÃ¬nh cÃ ng trá»Ÿ nÃªn phá»©c táº¡p vÃ  cáº§n nhiá»u dá»¯ liá»‡u hÆ¡n Ä‘á»ƒ huáº¥n luyá»‡n. Äiá»u nÃ y sáº½ khiáº¿n mÃ´ hÃ¬nh ráº¥t gáº§n vá»›i ngÃ´n ngá»¯ con ngÆ°á»i sá»­ dá»¥ng vÃ  Ã½ nghÄ©a cá»§a vÄƒn báº£n Ä‘Æ°á»£c diá»…n Ä‘áº¡t rÃµ rÃ ng.

**Lá»›p Ä‘áº§u ra (Output layer)**
CÃ¡c giÃ¡ trá»‹ áº©n tá»« hidden layers sau khi hoÃ n táº¥t sáº½ Ä‘Æ°á»£c truyá»n qua output layer Ä‘á»ƒ táº¡o ra dá»± Ä‘oÃ¡n cho tá»« tiáº¿p theo.\
Má»™t hÃ m kÃ­ch hoáº¡t sáº½ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ chuyá»ƒn Ä‘á»•i giÃ¡ trá»‹ áº©n thÃ nh má»™t pháº¡m vi cháº¥p nháº­n Ä‘Æ°á»£c cho dá»± Ä‘oÃ¡n. Má»™t cÃ¡ch Ä‘Æ¡n giáº£n nháº¥t Ä‘Ã³ lÃ  hÃ m `Softmax`. `Softmax` sáº½ chuyá»ƒn cÃ¡c giÃ¡ trá»‹ áº©n thÃ nh má»™t dÃ£y cÃ¡c tá»· lá»‡ cÃ¡c tá»« tiáº¿p theo cÃ³ thá»ƒ xuáº¥t hiá»‡n.\
VÃ  táº¥t nhiÃªn tá»« cÃ³ xÃ¡c suáº¥t xuáº¥t hiá»‡n cao nhÃ¢t sáº½ Ä‘Æ°á»£c chá»n lÃ m tá»« tiáº¿p theo trong cÃ¢u\
Äáº¿n Ä‘Ã¢y quÃ¡ trÃ¬nh dá»± Ä‘oÃ¡n má»™t tá»« Ä‘Ã£ hoÃ n thÃ nh. Cá»­a sá»• sáº½ tiáº¿p tá»¥c trÆ°á»£t xuá»‘ng má»™t tá»« vÃ  báº¯t Ä‘áº§u láº¡i quÃ¡ trÃ¬nh dá»¯ Ä‘oÃ¡n cho tá»« thá»© ${n+1} tiáº¿p theo

## **MÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (Large Language Models)**

MÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n lÃ  má»™t dáº¡ng mÃ´ hÃ¬nh mÃ¡y há»c Ä‘Æ°á»£c huáº¥n luyá»‡n trÃªn má»™t lÆ°á»£ng lá»›n dá»¯ liá»‡u ngÃ´n ngá»¯ tá»± nhiÃªn Ä‘á»ƒ hiá»ƒu vÃ  táº¡o ra vÄƒn báº£n ngÃ´n ngá»¯. Nhá»¯ng mÃ´ hÃ¬nh nÃ y thÆ°á»ng cÃ³ kÃ­ch thÆ°á»›c vÃ  Ä‘á»™ phá»©c táº¡p lá»›n, tháº­m chÃ­ cÃ³ thá»ƒ chá»©a hÃ ng tá»· tham sá»‘. DÆ°á»›i Ä‘Ã¢y lÃ  má»™t giáº£i thÃ­ch rÃµ rÃ ng vá» mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n.

### **Äáº·c Äiá»ƒm ChÃ­nh**
- MÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n thÆ°á»ng Ä‘Æ°á»£c huáº¥n luyá»‡n dá»¯ liá»‡u vÄƒn báº£n tá»« internet, sÃ¡ch, bÃ¡o, vÃ  cÃ¡c nguá»“n ngÃ´n ngá»¯ tá»± nhiÃªn khÃ¡c. Tá»« Ä‘Ã³ hiá»ƒu Ä‘Æ°á»£c quy luáº­t, cÃ¡ch cáº¥u trÃºc cÃ¢u, Ã½ nghÄ©a cá»§a cÃ¡c tá»«. 
- Nhá»¯ng dá»¯ liá»‡u vÄƒn báº£n nÃ y lÃ  vÃ´ cÃ¹ng lá»›n, lÃªn Ä‘áº¿n hÃ ng tetrabytes dá»¯ liá»‡u chá»¯.
- Äá»“ng thá»i vá»›i dá»¯ liá»‡u lá»›n thÆ°á»ng thá»i gian huáº¥n luyá»‡n sáº½ kÃ©o dÃ i tá»« hÃ ng tuáº§n cho Ä‘áº¿n hÃ ng thÃ¡ng vá»›i hÃ ng trÄƒm hÃ ng ngÃ n giá» huáº¥n luyá»‡n.
- CÃ¡c mÃ´ hÃ¬nh nÃ y thÆ°á»ng lÃ  cÃ¡c kiáº¿n trÃºc máº¡ng nÆ¡-ron sÃ¢u, cháº³ng háº¡n nhÆ° Transformer.
- Má»™t sá»‘ lá»›p (layer) cÃ³ thá»ƒ ká»ƒ Ä‘áº¿n nhÆ°:
    - *Embedding layer* chuyá»ƒn Ä‘á»•i tá»«ng tá»« trong vÄƒn báº£n Ä‘áº§u vÃ o thÃ nh biá»ƒu diá»…n vectÆ¡ nhiá»u chiá»u (high-dimensional). Nhá»¯ng vec-tÆ¡ nÃ y náº¯m báº¯t thÃ´ng tin ngá»¯ nghÄ©a vÃ  cÃº phÃ¡p cá»§a tá»«ng Ä‘Æ¡n vá»‹ cáº¥u táº¡o nÃªn cÃ¢u (tá»« hoáº·c token) vÃ  giÃºp mÃ´ hÃ¬nh hiá»ƒu Ä‘Æ°á»£c ngá»¯ cáº£nh cá»§a vÄƒn báº£n.
    - *Attention layers* lÃ  má»™t pháº§n quan trá»ng cá»§a LLM, cho phÃ©p mÃ´ hÃ¬nh táº­p trung cÃ³ chá»n lá»c vÃ o cÃ¡c pháº§n khÃ¡c nhau cá»§a vÄƒn báº£n Ä‘áº§u vÃ o. CÆ¡ cháº¿ nÃ y giÃºp mÃ´ hÃ¬nh chÃº Ã½ Ä‘áº¿n cÃ¡c pháº§n cÃ³ liÃªn quan nháº¥t cá»§a vÄƒn báº£n Ä‘áº§u vÃ o vÃ  táº¡o ra cÃ¡c dá»± Ä‘oÃ¡n chÃ­nh xÃ¡c hÆ¡n.
    - *Feedforward layers* gá»“m nhiá»u lá»›p Ä‘Æ°á»£c káº¿t ná»‘i Ä‘áº§y Ä‘á»§ Ã¡p dá»¥ng cÃ¡c phÃ©p biáº¿n Ä‘á»•i phi tuyáº¿n tÃ­nh cho cÃ¡c embedding vector Ä‘áº§u vÃ o. CÃ¡c lá»›p nÃ y giÃºp mÃ´ hÃ¬nh há»c cÃ¡c thÃ´ng tin trá»«u tÆ°á»£ng hÆ¡n tá»« vÄƒn báº£n Ä‘áº§u vÃ o.
    - *Recurrent layers* cá»§a LLM Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ diá»…n giáº£i thÃ´ng tin tá»« vÄƒn báº£n Ä‘áº§u vÃ o theo trÃ¬nh tá»±. CÃ¡c lá»›p nÃ y duy trÃ¬ tráº¡ng thÃ¡i áº©n Ä‘Æ°á»£c cáº­p nháº­t á»Ÿ má»—i bÆ°á»›c thá»i gian, cho phÃ©p mÃ´ hÃ¬nh náº¯m báº¯t Ä‘Æ°á»£c sá»± phá»¥ thuá»™c giá»¯a cÃ¡c tá»« trong cÃ¢u.


### **KÃ­ch ThÆ°á»›c vÃ  Sá»‘ LÆ°á»£ng Tham Sá»‘**
- MÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n thÆ°á»ng cÃ³ kÃ­ch thÆ°á»›c lá»›n, cÃ³ thá»ƒ chá»©a hÃ ng triá»‡u hay hÃ ng tá»· tham sá»‘.
- Sá»‘ lÆ°á»£ng tham sá»‘ lá»›n giÃºp mÃ´ hÃ¬nh há»c Ä‘Æ°á»£c biá»ƒu diá»…n phá»©c táº¡p cá»§a ngÃ´n ngá»¯ vÃ  ngá»¯ cáº£nh.

### **Pre-training vÃ  Fine-tunning**
**Pre-training**
- MÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c (pre-training) trÃªn lÆ°á»£ng lá»›n dá»¯ liá»‡u ngÃ´n ngá»¯ tá»± nhiÃªn.
- QuÃ¡ trÃ¬nh nÃ y giÃºp mÃ´ hÃ¬nh há»c Ä‘Æ°á»£c cÃ¡c Ä‘áº·c trÆ°ng ngÃ´n ngá»¯ tá»± nhiÃªn mÃ  khÃ´ng cáº§n thÃ´ng tin ngá»¯ cáº£nh cá»¥ thá»ƒ.

**Fine-tunning**
- Fine-tuning lÃ  quÃ¡ trÃ¬nh Ä‘iá»u chá»‰nh vÃ  cáº­p nháº­t cÃ¡c trá»ng sá»‘ cá»§a má»™t mÃ´ hÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c huáº¥n luyá»‡n trÆ°á»›c Ä‘Ã³ (pre-trained model) Ä‘á»ƒ phÃ¹ há»£p vá»›i má»™t táº­p dá»¯ liá»‡u má»›i hoáº·c nhiá»‡m vá»¥ cá»¥ thá»ƒ.
- Thay vÃ¬ huáº¥n luyá»‡n mÃ´ hÃ¬nh tá»« Ä‘áº§u, chÃºng ta sá»­ dá»¥ng kiáº¿n thá»©c Ä‘Ã£ Ä‘Æ°á»£c há»c tá»« má»™t mÃ´ hÃ¬nh ngÃ´n ngá»¯ cÃ³ sáºµn Ä‘á»ƒ nhanh chÃ³ng vÃ  hiá»‡u quáº£ hÃ³a quÃ¡ trÃ¬nh há»c cho táº­p dá»¯ liá»‡u má»›i.
- Sau quÃ¡ trÃ¬nh pre-training, mÃ´ hÃ¬nh cÃ³ thá»ƒ Ä‘Æ°á»£c fine-tuned trÃªn má»™t táº­p dá»¯ liá»‡u nhá» hoáº·c tÃ¡c vá»¥ cá»¥ thá»ƒ Ä‘á»ƒ tá»‘i Æ°u hÃ³a cho nhiá»‡m vá»¥ cá»¥ thá»ƒ nÃ o Ä‘Ã³.
- CÃ¡c tÃ¡c vá»¥ cá»¥ thá»ƒ cÃ³ thá»ƒ ká»ƒ Ä‘áº¿n nhÆ°: mÃ´ hÃ¬nh phiÃªn dá»‹ch, mÃ´ hÃ¬nh tráº£ lá»i cÃ¢u há»i (chatbot), gá»£i Ã½ cho ngÆ°á»i soáº¡n tháº£o vÄƒn báº£n, soáº¡n tháº£o code.

## **OpenAI vÃ  ChatGPT**

### **Generative Pre-training Transformer - GPT**

GPT lÃ  viáº¿t táº¯t cho Generative Pre-training Transformer, lÃ  má»™t mÃ´ hÃ¬nh ngÃ´n ngá»¯ tá»± nhiÃªn do chÃ­nh cÃ´ng ty OpenAI phÃ¡t triá»ƒn.\
GPT lÃ  mÃ´ hÃ¬nh ngÃ´n ngá»¯ dá»±a trÃªn máº¡ng nÆ¡ ron vá»›i kiáº¿n trÃºc phá»©c táº¡p vÃ  sá»‘ lÆ°á»£ng tham sá»‘ khá»•ng lá»“

Vá»›i GPT-3, sá»‘ lÆ°á»£ng tham sá»‘ lÃªn Ä‘áº¿n 175 tá»· vÃ  dá»¯ liá»‡u huáº¥n luyá»‡n khá»•ng lá»“: tá»« hÆ¡n 570GB Ä‘áº¿n khoáº£ng 45TB

Vá»›i lÆ°á»£ng tham sá»‘ khá»•ng lá»“ vÃ  mÃ£ hÃ³a cÃ¡c tá»« thÃ nh cÃ¡c vector Ä‘áº·c trÆ°ng, GPT-3 cÃ³ thá»ƒ hiá»ƒu Ä‘Æ°á»£c má»‘i quan há»‡ cÅ©ng nhÆ° Ã½ nghÄ©a cá»§a cÃ¡c tá»« vÃ  xÃ¢y dá»±ng má»™t cÃ¢u cÃ³ cáº¥u trÃºc Ä‘áº§y Ä‘á»§ Ã½ nghÄ©a.
<center><image src="https://i.imgur.com/zp9RQPR.png" width=30% height=30% /></center>

### **ChatGPT**

ChatGPT lÃ  á»©ng dá»¥ng do OpenAI phÃ¡t triá»ƒn dá»±a trÃªn mÃ´ hÃ¬nh ngÃ´n ngá»¯ GPT\
ChatGPT cÃ³ thá»ƒ Ä‘Æ¡n giáº£n Ä‘Æ°á»£c sá»­ dá»¥ng thÃ´ng qua web hoáº·c Ã¡p dá»¥ng vÃ o cÃ¡c á»©ng dá»¥ng thÃ´ng qua API cá»§a OpenAI

ChatGPT Ä‘Æ°á»£c tinh chá»‰nh (fine-tuning) tá»« mÃ´ hÃ¬nh pre-trained GPT trÃªn nhá»¯ng bá»™ dá»¯ liá»‡u táº­p trung vÃ o giao tiáº¿p cÅ©ng nhÆ° lÃ  há»™i thoáº¡i (tuy nhiÃªn hiá»‡n nÃ y OpenAI cÅ©ng chÆ°a cung cáº¥p Ä‘áº§y Ä‘á»§ cÃ¡c ná»™i dung Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ tinh chá»‰nh ChatGPT). Äiá»u nÃ y giÃºp ChatGPT hoáº¡t Ä‘á»™ng nhÆ° má»™t ngÆ°á»i trá»£ lÃ½ vÃ  cÃ³ thá»ƒ tráº£ lá»i cÃ¢u há»i cÅ©ng nhÆ° trÃ² chuyá»‡n vá»›i ngÆ°á»i dÃ¹ng.

#### **Má»™t sá»‘ chá»©c nÄƒng**



- **Há»— Trá»£ vÃ  Tráº£ Lá»i CÃ¢u Há»i:**\
ChatGPT cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ tráº£ lá»i cÃ¡c cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng vá» nhiá»u chá»§ Ä‘á» khÃ¡c nhau.

- **Táº¡o Ná»™i Dung VÄƒn Báº£n:**\
CÃ³ thá»ƒ sá»­ dá»¥ng Ä‘á»ƒ táº¡o vÄƒn báº£n sÃ¡ng táº¡o, viáº¿t bÃ i, hoáº·c táº¡o ná»™i dung cho cÃ¡c á»©ng dá»¥ng khÃ¡c.

- **Há»— Trá»£ Viá»‡c Há»c:**\
DÃ¹ng Ä‘á»ƒ giáº£i bÃ i toÃ¡n, giáº£i Ä‘Ã¡p tháº¯c máº¯c, hoáº·c há»— trá»£ trong quÃ¡ trÃ¬nh há»c táº­p.

- **Giao Tiáº¿p vÃ  TrÃ² Chuyá»‡n:**\
CÃ³ thá»ƒ sá»­ dá»¥ng Ä‘á»ƒ tÆ°Æ¡ng tÃ¡c vÃ  trÃ² chuyá»‡n vá»›i ngÆ°á»i dÃ¹ng, giáº£ láº­p vai trÃ² cá»§a má»™t Ä‘á»‘i tÃ¡c trÃ² chuyá»‡n.

- **PhÃ¢n Loáº¡i VÄƒn Báº£n:**\
Ãp dá»¥ng Ä‘á»ƒ phÃ¢n loáº¡i vÄƒn báº£n, nháº­n biáº¿t cáº£m xÃºc, hoáº·c phÃ¢n loáº¡i ná»™i dung vÄƒn báº£n theo cÃ¡c Ä‘áº·c Ä‘iá»ƒm nháº¥t Ä‘á»‹nh.

- **Táº¡o áº¢nh HÃ³a Ná»™i Dung:**\
DÃ¹ng Ä‘á»ƒ biá»ƒu diá»…n thÃ´ng tin vÄƒn báº£n dÆ°á»›i dáº¡ng hÃ¬nh áº£nh, táº¡o visualizations cho dá»¯ liá»‡u vÄƒn báº£n.

- **Há»— Trá»£ SÃ¡ng Táº¡o vÃ  TÃ¬m Kiáº¿m Ã TÆ°á»Ÿng:**\
GiÃºp ngÆ°á»i dÃ¹ng tÃ¬m kiáº¿m Ã½ tÆ°á»Ÿng sÃ¡ng táº¡o, táº¡o ra cÃ¢u chuyá»‡n, hay khÃ¡m phÃ¡ cÃ¡c khÃ­a cáº¡nh má»›i trong má»™t chá»§ Ä‘á» nÃ o Ä‘Ã³.

#### **CÃ¡ch hoáº¡t Ä‘á»™ng**

<center><image src="https://i.imgur.com/hoRTVVx.png" height=70% width=70%/></center>


ChatGPT lÃ  má»™t máº¡ng nÆ¡ ron háº¿t sá»©c phá»©c táº¡p, hÃ¬nh minh há»a trÃªn cÅ©ng chá»‰ lÃ  tÃ³m táº¯t rÃºt gá»n cÃ²n má»™t pháº§n quÃ¡ trÃ¬nh. Trong thá»±c táº¿, ChatGPT cÃ³ ráº¥t nhiá»u khá»‘i (blocks) xá»­ lÃ½ nhÆ° váº­y trÆ°á»›c khi cho ra output thá»±c sá»±.
Má»™t cÃ¡ch Ä‘Æ¡n giáº£n dá»±a trÃªn mÃ´ hÃ¬nh tÃ³m táº¯t trÃªn, quÃ¡ trÃ¬nh tiáº¿p nháº­n cÃ¢u há»i, xá»­ lÃ½, tÃ­nh toÃ¡n vÃ  Ä‘Æ°a ra cÃ¢u tráº£ lá»i cÃ³ thá»ƒ tÃ³m táº¯t nhÆ° sau:

**Chuyá»ƒn hÃ³a thÃ nh cÃ¡c vector Ä‘áº·c trÆ°ng**

CÃ¢u Ä‘áº§u vÃ o sáº½ Ä‘Æ°á»£c tÃ¡ch thÃ nh cÃ¡c tá»« hoáº·c chuá»—i tá»« nhá» hÆ¡n vÃ  Ä‘Æ°á»£c chuyá»ƒn hÃ³a thÃ nh má»™t vector Ä‘áº·c trÆ°ng.\
Vector Ä‘áº·c trÆ°ng nÃ y sáº½ mang Ä‘áº·c trÆ°ng cá»§a tá»« ngá»¯ vÃ  Ã½ nghÄ©a sáº½ Ä‘Æ°á»£c táº§ng self attention phÃ¢n tÃ­ch má»‘i quan há»‡ tá»« Ä‘Ã³ hiá»ƒu rÃµ Ã½ nghÄ©a ná»™i dung cá»§a cÃ¢u.

**Self Attention Layer**

Trong mÃ´ hÃ¬nh ngÃ´n ngá»¯ nhÆ° ChatGPT, "self-attention layer" lÃ  má»™t thÃ nh pháº§n quan trá»ng trong kiáº¿n trÃºc Transformer. Cá»¥ thá»ƒ, nÃ³ Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ xá»­ lÃ½ thÃ´ng tin tá»« táº¥t cáº£ cÃ¡c tá»« trong cÃ¢u Ä‘áº§u vÃ o Ä‘á»“ng thá»i, giÃºp mÃ´ hÃ¬nh hiá»ƒu Ä‘Æ°á»£c má»‘i quan há»‡ giá»¯a cÃ¡c tá»« vÃ  táº¡o ra biá»ƒu diá»…n ngá»¯ cáº£nh cho má»—i tá»« dá»±a trÃªn ngá»¯ cáº£nh xung quanh nÃ³.

TÃ­nh nÄƒng chÃ­nh cá»§a self-attention layer bao gá»“m:

- *ChÃº Ã½ Ä‘á»“ng thá»i Ä‘áº¿n táº¥t cáº£ cÃ¡c vá»‹ trÃ­:* Má»—i tá»« trong cÃ¢u cÃ³ thá»ƒ tÆ°Æ¡ng tÃ¡c vá»›i táº¥t cáº£ cÃ¡c tá»« khÃ¡c thÃ´ng qua trá»ng sá»‘ chÃº Ã½. Äiá»u nÃ y giÃºp mÃ´ hÃ¬nh hiá»ƒu Ä‘Æ°á»£c cÃ¡ch má»—i tá»« áº£nh hÆ°á»Ÿng Ä‘áº¿n cÃ¡c tá»« khÃ¡c vÃ  cÅ©ng giÃºp xá»­ lÃ½ cÃ¡c má»‘i quan há»‡ khÃ´ng cá»‘ Ä‘á»‹nh giá»¯a cÃ¡c tá»«.

- *Biá»ƒu diá»…n ngá»¯ cáº£nh:* Self-attention layer giÃºp táº¡o ra má»™t biá»ƒu diá»…n ngá»¯ cáº£nh cho má»—i tá»« dá»±a trÃªn thÃ´ng tin tá»« táº¥t cáº£ cÃ¡c tá»« khÃ¡c trong cÃ¢u. Äiá»u nÃ y cung cáº¥p má»™t cÃ¡ch hiá»‡u quáº£ Ä‘á»ƒ mÃ´ hÃ¬nh "hiá»ƒu" ngá»¯ cáº£nh cá»§a cÃ¢u vÃ  dá»± Ä‘oÃ¡n tá»« tiáº¿p theo trong chuá»—i.

- *Kháº£ nÄƒng xá»­ lÃ½ chuá»—i dÃ i:* Do self-attention layer cÃ³ kháº£ nÄƒng xá»­ lÃ½ toÃ n bá»™ chuá»—i Ä‘áº§u vÃ o Ä‘á»“ng thá»i, nÃ³ giÃºp mÃ´ hÃ¬nh giáº£i quyáº¿t váº¥n Ä‘á» vanishing gradient (gradient biáº¿n máº¥t) khi xá»­ lÃ½ chuá»—i dÃ i, lÃ  má»™t váº¥n Ä‘á» phá»• biáº¿n trong cÃ¡c mÃ´ hÃ¬nh sá»­ dá»¥ng kiáº¿n trÃºc RNN (Recurrent Neural Network) truyá»n thá»‘ng.

**Feedforward Neural Network**

Feedforward layer trong kiáº¿n trÃºc cá»§a mÃ´ hÃ¬nh nhÆ° ChatGPT thÆ°á»ng Ä‘Æ°á»£c sá»­ dá»¥ng sau cÃ¡c lá»›p tá»± chÃº Ã½ (self-attention layers) trong cÃ¡c mÃ´ hÃ¬nh Transformer. Feedforward layer chá»§ yáº¿u thá»±c hiá»‡n cÃ¡c phÃ©p biáº¿n Ä‘á»•i phi tuyáº¿n tÃ­nh Ä‘Æ¡n giáº£n cho cÃ¡c biá»ƒu diá»…n Ä‘áº§u vÃ o tá»« cÃ¡c lá»›p tá»± chÃº Ã½. DÆ°á»›i Ä‘Ã¢y lÃ  má»™t sá»‘ Ä‘iá»ƒm quan trá»ng vá» tÃ¡c dá»¥ng cá»§a feedforward layer:

- *Biáº¿n Ä‘á»•i phi tuyáº¿n tÃ­nh:* Feedforward layer thÆ°á»ng thá»±c hiá»‡n cÃ¡c phÃ©p biáº¿n Ä‘á»•i phi tuyáº¿n tÃ­nh cho tá»«ng vá»‹ trÃ­ Ä‘áº§u vÃ o Ä‘á»™c láº­p. Äiá»u nÃ y giÃºp mÃ´ hÃ¬nh há»c Ä‘Æ°á»£c cÃ¡c má»‘i quan há»‡ phá»©c táº¡p vÃ  biá»ƒu diá»…n cÃ¡c Ä‘áº·c trÆ°ng phá»©c táº¡p cá»§a dá»¯ liá»‡u Ä‘áº§u vÃ o.

- *Má»Ÿ rá»™ng khÃ´ng gian Ä‘áº·c trÆ°ng:* Báº±ng cÃ¡ch sá»­ dá»¥ng cÃ¡c hÃ m kÃ­ch thÃ­ch phi tuyáº¿n tÃ­nh, feedforward layer giÃºp mÃ´ hÃ¬nh táº¡o ra cÃ¡c biá»ƒu diá»…n cÃ³ chiá»u sÃ¢u hÆ¡n, má»Ÿ rá»™ng khÃ´ng gian Ä‘áº·c trÆ°ng cá»§a dá»¯ liá»‡u. Äiá»u nÃ y cÃ³ thá»ƒ giÃºp mÃ´ hÃ¬nh há»c Ä‘Æ°á»£c cÃ¡c biá»ƒu diá»…n phá»©c táº¡p hÆ¡n vÃ  thÃ­ch á»©ng tá»‘t hÆ¡n vá»›i dá»¯ liá»‡u Ä‘a dáº¡ng.

- *Giáº£m chiá»u cá»§a biá»ƒu diá»…n:* ThÃ´ng thÆ°á»ng, sau khi thá»±c hiá»‡n phÃ©p biáº¿n Ä‘á»•i phi tuyáº¿n tÃ­nh, mÃ´ hÃ¬nh cÃ³ thá»ƒ sá»­ dá»¥ng cÃ¡c ká»¹ thuáº­t nhÆ° hÃ m kÃ­ch thÃ­ch (activation function) vÃ  dropout Ä‘á»ƒ tinh chá»‰nh vÃ  giáº£m chiá»u cá»§a biá»ƒu diá»…n Ä‘áº§u ra. Äiá»u nÃ y giÃºp kiá»ƒm soÃ¡t sá»‘ lÆ°á»£ng tham sá»‘ cá»§a mÃ´ hÃ¬nh vÃ  trÃ¡nh tÃ¬nh tráº¡ng overfitting.

- *TÄƒng tÃ­nh tÆ°Æ¡ng tÃ¡c khÃ´ng gian:* Feedforward layer táº¡o ra cÃ¡c tÆ°Æ¡ng tÃ¡c khÃ´ng gian giá»¯a cÃ¡c thÃ nh pháº§n cá»§a biá»ƒu diá»…n Ä‘áº§u vÃ o, giÃºp mÃ´ hÃ¬nh há»c Ä‘Æ°á»£c cÃ¡c má»‘i quan há»‡ phá»©c táº¡p vÃ  tÆ°Æ¡ng tÃ¡c giá»¯a cÃ¡c Ä‘áº·c trÆ°ng.

**Final Transform Layer**

Thá»±c táº¿ ChatGPT khÃ´ng cÃ³ lá»›p Final Transform Layer chuyÃªn biá»‡t mÃ  thay vÃ o Ä‘Ã³ á»Ÿ cuá»‘i má»—i block sáº½ cÃ³ má»™t lá»›p Normalization vÃ  má»™t lá»›p Feedforward Layer

**Lá»›p Normalization (Layer Normalization):**

- *TÃ¡c dá»¥ng:* Lá»›p normalization giÃºp chuáº©n hÃ³a giÃ¡ trá»‹ Ä‘áº§u ra tá»« lá»›p tá»± chÃº Ã½ Ä‘á»ƒ giá»¯ cho cÃ¡c Ä‘áº·c trÆ°ng cÃ³ giÃ¡ trá»‹ gáº§n báº±ng nhau vÃ  dá»… quáº£n lÃ½ hÆ¡n trong quÃ¡ trÃ¬nh há»c.
- *Æ¯u Ä‘iá»ƒm:* GiÃºp kiá»ƒm soÃ¡t gradient, giáº£m hiá»‡n tÆ°á»£ng vanishing/exploding gradient, vÃ  cáº£i thiá»‡n sá»± há»™i tá»¥ cá»§a mÃ´ hÃ¬nh.
- *CÆ¡ cháº¿ hoáº¡t Ä‘á»™ng:* Chuáº©n hÃ³a Ä‘Æ°á»£c thá»±c hiá»‡n báº±ng cÃ¡ch trá»« Ä‘i giÃ¡ trá»‹ trung bÃ¬nh cá»§a Ä‘áº§u ra vÃ  chia cho Ä‘á»™ lá»‡ch chuáº©n. Äiá»u nÃ y giÃºp Ä‘áº§u ra cá»§a lá»›p cÃ³ mean báº±ng 0 vÃ  Ä‘á»™ lá»‡ch chuáº©n báº±ng 1.

**Lá»›p Feedforward:**

- *TÃ¡c dá»¥ng:* Lá»›p feedforward thá»±c hiá»‡n cÃ¡c phÃ©p biáº¿n Ä‘á»•i phi tuyáº¿n tÃ­nh Ä‘Æ¡n giáº£n cho má»—i vá»‹ trÃ­ Ä‘áº§u vÃ o Ä‘á»™c láº­p, giÃºp mÃ´ hÃ¬nh há»c Ä‘Æ°á»£c cÃ¡c má»‘i quan há»‡ phá»©c táº¡p giá»¯a cÃ¡c Ä‘áº·c trÆ°ng.
- *CÆ¡ cháº¿ hoáº¡t Ä‘á»™ng:* Má»—i Ä‘áº§u vÃ o táº¡i má»—i vá»‹ trÃ­ Ä‘Æ°á»£c Ä‘Æ°a qua má»™t lá»›p káº¿t ná»‘i Ä‘áº§y Ä‘á»§ vá»›i cÃ¡c trá»ng sá»‘ tuyáº¿n tÃ­nh vÃ  hÃ m kÃ­ch thÃ­ch phi tuyáº¿n tÃ­nh. Äiá»u nÃ y táº¡o ra Ä‘áº§u ra má»›i táº¡i má»—i vá»‹ trÃ­.

**Dá»± Ä‘oÃ¡n tá»« tiáº¿p theo**

MÃ´ hÃ¬nh GPT lÃ  má»™t mÃ´ hÃ¬nh ngÃ´n ngá»¯ tá»± Ä‘á»™ng sinh (autoregressive), cÃ³ nghÄ©a lÃ  nÃ³ táº¡o ra cÃ¢u tráº£ lá»i tá»«ng tá»« má»™t theo thá»© tá»± tuáº§n tá»±.\
MÃ´ hÃ¬nh sá»­ dá»¥ng káº¿t quáº£ tá»« lá»›p feedforward Ä‘á»ƒ dá»± Ä‘oÃ¡n tá»« tiáº¿p theo trong chuá»—i.\
QuÃ¡ trÃ¬nh nÃ y Ä‘Æ°á»£c láº·p láº¡i cho Ä‘áº¿n khi cÃ¢u tráº£ lá»i Ä‘á»§ dÃ i hoáº·c Ä‘iá»u kiá»‡n dá»«ng Ä‘Æ°á»£c Ä‘áº¡t Ä‘áº¿n.

**Output**
Ná»™i dung vÄƒn báº£n tráº£ lá»i sáº½ Ä‘Æ°á»£c tráº£ vá» cho ngÆ°á»i dÃ¹ng

#### **Æ¯u vÃ  nhÆ°á»£c Ä‘iá»ƒm**

**Æ¯u Ä‘iá»ƒm**

- *Sá»± Linh Hoáº¡t:* ChatGPT lÃ  má»™t mÃ´ hÃ¬nh ngÃ´n ngá»¯ máº¡nh máº½ cÃ³ kháº£ nÄƒng xá»­ lÃ½ nhiá»u loáº¡i nhiá»‡m vá»¥. NÃ³ cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng cho viá»‡c táº¡o vÄƒn báº£n, tÆ° váº¥n thÃ´ng tin, giáº£i bÃ i toÃ¡n, vÃ  nhiá»u á»©ng dá»¥ng khÃ¡c.

- *TÃ­nh SÃ¡ng táº¡o:* MÃ´ hÃ¬nh cÃ³ kháº£ nÄƒng táº¡o ra ná»™i dung sÃ¡ng táº¡o vÃ  Ä‘á»™c Ä‘Ã¡o, giÃºp ngÆ°á»i dÃ¹ng thá»±c hiá»‡n cÃ´ng viá»‡c sÃ¡ng táº¡o vÃ  phÃ¡t triá»ƒn Ã½ tÆ°á»Ÿng má»›i.

- *Há»— trá»£ Nhanh chÃ³ng:* ChatGPT cÃ³ thá»ƒ cung cáº¥p cÃ¢u tráº£ lá»i nhanh chÃ³ng cho nhiá»u cÃ¢u há»i vÃ  váº¥n Ä‘á» khÃ¡c nhau, giÃºp tÄƒng cÆ°á»ng hiá»‡u suáº¥t vÃ  tiáº¿t kiá»‡m thá»i gian.

- *Dá»… sá»­ dá»¥ng:* Vá»›i giao diá»‡n web thÃ¢n thiá»‡n vÃ  dá»… dÃ¹ng, ngÆ°á»i dÃ¹ng cÃ³ thá»ƒ sá»­ dá»¥ng ChatGPT á»Ÿ báº¥t kÃ¬ Ä‘Ã¢u, Ä‘á»“ng thá»i cÅ©ng cÃ³ thá»ƒ Ã¡p dá»¥ng API cá»§a OpenAI vÃ o cÃ¡c á»©ng dá»¥ng phÃ¡t triá»ƒn bá»Ÿi láº­p trÃ¬nh viÃªn

**NhÆ°á»£c Ä‘iá»ƒm**
- *Hiá»ƒu biáº¿t háº¡n cháº¿:* ChatGPT cÃ³ thá»ƒ khÃ´ng hiá»ƒu rÃµ ngá»¯ cáº£nh hoáº·c yÃªu cáº§u thÃ´ng tin thÃªm Ä‘á»ƒ Ä‘Æ°a ra cÃ¢u tráº£ lá»i chÃ­nh xÃ¡c. Äiá»u nÃ y cÃ³ thá»ƒ dáº«n Ä‘áº¿n thÃ´ng tin khÃ´ng chÃ­nh xÃ¡c hoáº·c hiá»ƒu láº§m.

- *Rá»§i ro Ä‘á»™ chÃ­nh xÃ¡c:* Máº·c dÃ¹ cÃ³ thá»ƒ sÃ¡ng táº¡o, nhÆ°ng ChatGPT cÅ©ng cÃ³ kháº£ nÄƒng táº¡o ra thÃ´ng tin khÃ´ng chÃ­nh xÃ¡c, khÃ´ng phÃ¹ há»£p hoáº·c thiáº¿u tÃ­nh phÃ¢n biá»‡t.

- *Báº£o máº­t vÃ  Quyá»n RiÃªng tÆ°:* CÃ¡c váº¥n Ä‘á» liÃªn quan Ä‘áº¿n báº£o máº­t vÃ  quyá»n riÃªng tÆ° cÃ³ thá»ƒ náº£y sinh khi sá»­ dá»¥ng ChatGPT, Ä‘áº·c biá»‡t lÃ  khi xá»­ lÃ½ thÃ´ng tin nháº¡y cáº£m.

- *Phá»¥ thuá»™c vÃ o Dá»¯ liá»‡u ÄÃ o táº¡o:* Hiá»‡u suáº¥t cá»§a ChatGPT phá»¥ thuá»™c nhiá»u vÃ o dá»¯ liá»‡u Ä‘Ã o táº¡o, cÃ³ thá»ƒ dáº«n Ä‘áº¿n sá»± thiÃªn lá»‡ch hoáº·c háº¡n cháº¿ trong quy mÃ´ vÃ  Ä‘a dáº¡ng cá»§a thÃ´ng tin mÃ  mÃ´ hÃ¬nh cÃ³ thá»ƒ hiá»ƒu vÃ  táº¡o ra.

TÃ³m láº¡i, tuy ChatGPT mang láº¡i nhiá»u lá»£i Ã­ch, nhÆ°ng viá»‡c nháº­n biáº¿t vÃ  quáº£n lÃ½ nhÆ°á»£c Ä‘iá»ƒm cá»§a nÃ³ lÃ  quan trá»ng Ä‘á»ƒ Ä‘áº£m báº£o sá»­ dá»¥ng cÃ³ hiá»‡u quáº£ vÃ  an toÃ n.

## **Giá»›i thiá»‡u vá» JoyImage**

JoyImage lÃ  má»™t website Ä‘Æ°á»£c xÃ¢y dá»±ng Ä‘Æ¡n giáº£n báº±ng Streamlit vÃ  ngÃ´n ngá»¯ láº­p trÃ¬nh Python.

ThÃ´ng qua JoyImage, má»i ngÆ°á»i cÃ³ thá»ƒ tá»± do sÃ¡ng táº¡o ra nhá»¯ng bá»©c áº£nh Æ°ng Ã½, báº±ng nhiá»u cÃ´ng cá»¥ khÃ¡c nhau vá»›i sá»± há»— trá»£ máº¡nh máº½ tá»« ChatGPT 

CÃ¡c cÃ´ng cá»¥ cÃ³ thá»ƒ sá»­ dá»¥ng Ä‘á»ƒ táº¡o áº£nh lÃ :
- **Táº¡o áº£nh tá»« nhá»¯ng Ä‘á» tÃ i vÃ  má»¥c Ä‘Ã£ chá»n (categories and selections):** NgÆ°á»i dÃ¹ng cÃ³ thá»ƒ lá»±a chá»n Ä‘á» tÃ i cho bá»©c tranh, lá»±a chá»n nhá»¯ng ná»™i dung, váº­t thá»ƒ, quang cáº£nh cÃ³ trong Ä‘á» tÃ i Ä‘Ã³ hoáº·c sÃ¡ng táº¡o hÆ¡n lÃ  káº¿t há»£p nhiá»u Ä‘á» tÃ i khÃ¡c nhau Ä‘á»ƒ táº¡o ra nhá»¯ng bá»©c áº£nh tuyá»‡t Ä‘áº¹p. CÃ¡c lá»±a chá»n sau khi Ä‘Æ°á»£c chá»n sáº½ Ä‘Æ°á»£c Ä‘Æ°a cho ChatGPT Ä‘á»ƒ sinh ra má»™t Ä‘oáº¡n vÄƒn báº£n (prompt) Ä‘á»ƒ cho AI sÃ¡ng táº¡o áº£nh.
- **Táº¡o áº£nh tá»« giá»ng nÃ³i:** NgÆ°á»i dÃ¹ng cÃ³ thá»ƒ thu Ã¢m trá»±c tiáº¿p trÃªn website vÃ  giá»ng nÃ³i tiáº¿ng Viá»‡t sáº½ Ä‘Æ°á»£c chuyá»ƒn thÃ nh vÄƒn báº£n. Vá»›i vÄƒn báº£n nÃ y ngÆ°á»i dÃ¹ng cÃ³ thá»ƒ dÃ¹ng Ä‘á»ƒ sÃ¡ng táº¡o áº£nh trá»±c tiáº¿p hoáº·c nhá» sá»± trá»£ giÃºp cá»§a ChatGPT Ä‘Æ°á»£c tÃ­ch há»£p sáºµn trÃªn website Ä‘á»ƒ lÃ m cÃ¢u vÄƒn mÆ°á»£t mÃ  hÆ¡n vÃ  hÃ¬nh áº£nh sáº½ Ä‘áº¹p hÆ¡n.
- **Táº¡o áº£nh tá»« vÄƒn báº£n:** Má»™t cÃ¡ch Ä‘Æ¡n giáº£n, ngÆ°á»i dÃ¹ng nháº­p nhá»¯ng gÃ¬ mÃ¬nh muá»‘n cÃ³ trong bá»©c áº£nh vÃ o vÃ  yÃªu cáº§u AI sÃ¡ng táº¡o cho mÃ¬nh bá»©c áº£nh tÆ°Æ¡ng tá»±. Tuy nhiÃªn má»™t chá»©c nÄƒng Ä‘Æ°á»£c tÃ­ch há»£p Ä‘Ã³ lÃ  sá»± há»— trá»£ tá»« ChatGPT cÃ³ thá»ƒ giÃºp cÃ¢u vÄƒn dá»… hiá»ƒu, Ä‘áº§y Ä‘á»§ ná»™i dung vÃ  bá»©c áº£nh sáº½ Ä‘áº¹p hÆ¡n, Ä‘Ãºng Ã½ ngÆ°á»i dÃ¹ng hÆ¡n.

### **CÃ´ng nghá»‡ sá»­ dá»¥ng**
Nhá»¯ng cÃ´ng nghá»‡ mÃ  JoyImage sá»­ dá»¥ng lÃ :
- **Python 3.11.4:** Python lÃ  má»™t ngÃ´n ngá»¯ láº­p trÃ¬nh Ä‘á»™ng máº¡nh máº½ vÃ  Ä‘a nÄƒng, Ä‘áº·c biá»‡t Ä‘Æ°á»£c Æ°a chuá»™ng trong lÄ©nh vá»±c trÃ­ tuá»‡ nhÃ¢n táº¡o (AI). Vá»›i cá»™ng Ä‘á»“ng lá»›n, thÆ° viá»‡n phong phÃº nhÆ° NumPy, Pandas, vÃ  scikit-learn, Python lÃ  sá»± lá»±a chá»n hÃ ng Ä‘áº§u cho viá»‡c phÃ¡t triá»ƒn mÃ´ hÃ¬nh mÃ¡y há»c vÃ  xá»­ lÃ½ dá»¯ liá»‡u trong lÄ©nh vá»±c AI.
- **Streamlit:** Streamlit lÃ  má»™t thÆ° viá»‡n Python mÃ£ nguá»“n má»Ÿ Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ táº¡o á»©ng dá»¥ng web Ä‘Æ°á»£c import vÃ o Python Ä‘á»ƒ há»— trá»£ xÃ¢y dá»±ng má»™t trang website Ä‘áº¹p, Ä‘Æ¡n giáº£n vÃ  dá»… dÃ¹ng báº±ng ngÃ´n ngá»¯ láº­p trÃ¬nh Python.
- **CSS:** CSS Ä‘Æ°á»£c sá»­ dá»¥ng chá»§ yáº¿u Ä‘á»ƒ Ä‘á»‹nh dáº¡ng vÃ  trÃ¬nh bÃ y trang web Ä‘Æ°á»£c viáº¿t báº±ng HTML. Do Ä‘Æ¡n giáº£n, cÃ¡c thiáº¿t káº¿ giao diá»‡n web cá»§a Streamlit sinh ra khÃ¡ cÆ¡ báº£n vÃ  nhÃ m chÃ¡n. Do Ä‘Ã³ cáº§n má»™t vÃ i thay Ä‘á»•i dá»±a trÃªn má»™t vÃ i Ä‘oáº¡n mÃ£ CSS Ä‘á»ƒ thay Ä‘á»•i giao diá»‡n, lÃ m chÃºng trá»Ÿ nÃªn báº¯t máº¯t vÃ  thÃº vá»‹ hÆ¡n.
- **Stable Diffusion - Openjourney:** Stable Diffusion lÃ  má»™t mÃ´ hÃ¬nh trÃ­ tuá»‡ nhÃ¢n táº¡o táº¡o sinh (lÃ  má»™t pre-trained model) cÃ³ kháº£ nÄƒng táº¡o ra hÃ¬nh áº£nh táº£ thá»±c Ä‘á»™c Ä‘Ã¡o tá»« lá»i nháº¯c báº±ng vÄƒn báº£n vÃ  hÃ¬nh áº£nh. Äiá»u Ä‘áº·c biá»‡t lÃ  Stable Diffusion hoÃ n toÃ n má»Ÿ cáº£ vá» mÃ£ nguá»“n vÃ  trá»ng sá»‘ cá»§a mÃ´ hÃ¬nh. Do Ä‘Ã³ má»i ngÆ°á»i cÃ³ thá»ƒ tinh chá»‰nh (fine-tunning) trÃªn mÃ´ hÃ¬nh nÃ y vÃ  táº¡o ra nhá»¯ng mÃ´ hÃ¬nh mong muá»‘n. Openjourney lÃ  má»™t mÃ´ hÃ¬nh Ä‘Æ°á»£c cÃ´ng bá»‘ trÃªn HuggingFace Ä‘Æ°á»£c tinh chá»‰nh trÃªn Stable Diffusion trÃªn nhá»¯ng bá»©c áº£nh tá»« MidJourney. ÄÃ¢y lÃ  cÃ´ng nghá»‡ chÃ­nh cá»§a trang web Ä‘á»ƒ sÃ¡ng táº¡o ra nhá»¯ng bá»©c áº£nh mÃ  ngÆ°á»i dÃ¹ng mong muá»‘n. á» Ä‘Ã¢y website gá»i thÃ´ng qua API tá»« HuggingFace.
- **Google Speech Recognition:** ÄÆ°á»£c gá»i thÃ´ng qua thÆ° viá»‡n SpeechRecognition sá»­ dá»¥ng Google Cloud Speech API. CÃ´ng nghá»‡ nÃ y Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ nháº­n diá»‡n lá»i nÃ³i cá»§a ngÆ°á»i dÃ¹ng vÃ  chuyá»ƒn Ä‘á»•i thÃ nh vÄƒn báº£n.
- **Google Translate:** ÄÆ°á»£c gá»i thÃ´ng qua thÆ° viá»‡n googletrans sá»­ dá»¥ng Google Translate API Ä‘á»ƒ dá»‹ch vÄƒn báº£n tiáº¿ng Viá»‡t cá»§a ngÆ°á»i dÃ¹ng sang tiáº¿ng Anh. Viá»‡c dá»‹ch sang tiáº¿ng Anh giÃºp cÃ¡c tÃ¡c vá»¥ sau cÃ³ thá»ƒ xá»­ lÃ­ hiá»‡u quáº£ hÆ¡n.
- **ChatGPT-3.5:** ÄÆ°á»£c gá»i thÃ´ng qua API cá»§a OpenAI ChatGPT há»— trá»£ ngÆ°á»i dÃ¹ng xÃ¢y dá»±ng má»™t Ä‘oáº¡n prompt hoÃ n chá»‰nh, ná»™i dung rÃµ rÃ ng Ä‘á»ƒ Stable Diffusion dá»… dÃ ng sÃ¡ng táº¡o ra má»™t bá»©c áº£nh Ä‘áº¹p Æ°ng Ã½ vá»›i ngÆ°á»i dÃ¹ng.

<center><image alt="Giao diá»‡n chÃ­nh" src="https://i.imgur.com/lSTa9aC.png" width = 50% height = 50%/></center>

### **Táº¡o áº£nh tá»« nhá»¯ng Ä‘á» tÃ i vÃ  má»¥c Ä‘Ã£ chá»n**

#### **Chá»n chá»§ Ä‘á»**



á» giao diá»‡n chÃ­nh cá»§a trang web:
- Má»™t dropdown cÃ³ thá»ƒ sá»­ dá»¥ng Ä‘á»ƒ chá»n chá»§ Ä‘á» cho bá»©c áº£nh.

<center><image alt="dropdown" src="https://i.imgur.com/ivGmfKD.png" width=50% height=50% /> </center>

#### **Chá»n má»¥c lá»±a chá»n**


- CÃ¡c má»¥c thuá»™c vÃ o chá»§ Ä‘á» Ä‘Ã£ chá»n sáº½ xuáº¥t hiá»‡n vÃ  báº¡n cÃ³ thá»ƒ lá»±a chá»n cho bá»©c áº£nh
<center><image alt="Giao diá»‡n chÃ­nh" src="https://i.imgur.com/lSTa9aC.png" width = 50% height = 50%/></center>

- á» Ä‘Ã¢y ta thá»­ lá»±a chá»n Ao cÃ¡, Ngá»“i lÃ ng vÃ  CÃ¡nh Ä‘á»“ng hoa


#### **SÃ¡ng táº¡o áº£nh**


- LÆ°á»›t phÃ­a dÆ°á»›i cÃ³ má»™t lá»±a chá»n Ä‘á»ƒ sÃ¡ng táº¡o áº£nh ngay

<center><image alt="Giao diá»‡n chÃ­nh" src="https://i.imgur.com/vKUtomN.png" width = 50% height = 50%/></center>

- Nháº¥n vÃ o nÃºt nháº¥n nÃ y vÃ  Ä‘á»£i má»™t chÃºt

<center><image alt="Giao diá»‡n chÃ­nh" src="https://i.imgur.com/KvKYlhD.png" width = 50% height = 50%/></center>

- Váº­y lÃ  má»™t bá»©c áº£nh tuyá»‡t vá»i Ä‘Ã£ Ä‘Æ°á»£c sÃ¡ng táº¡o chá»‰ trong vÃ i giÃ¢y


### **Táº¡o áº£nh tá»« giá»ng nÃ³i**

#### **Thu Ã¢m**

- Chá»n má»¥c Giá»ng NÃ³i tá»« menu bÃªn trÃ¡i mÃ n hÃ¬nh.
- Chá»n thu Ã¢m vÃ  báº¯t Ä‘áº§u nÃ³i vÃ o micro cá»§a mÃ¬nh.
- Giá»ng nÃ³i sáº½ Ä‘Æ°á»£c chuyá»ƒn thÃ nh vÄƒn báº£n vÃ  cho phÃ©p ngÆ°á»i dÃ¹ng chá»‰nh sá»­a.

<center><image src="https://i.imgur.com/hy3g9kF.png" width = 50% height = 50%></center>

#### **Lá»±a chá»n phÆ°Æ¡ng thá»©c sÃ¡ng táº¡o**

NgÆ°á»i dÃ¹ng cÃ³ thá»ƒ chá»n giá»¯a sÃ¡ng táº¡o ngay hoáº·c há»— trá»£ cá»§a AI:
- Lá»±a chá»n sÃ¡ng táº¡o ngay sáº½ táº¡o áº£nh tá»« chÃ­nh vÄƒn báº£n sinh ra tá»« vÄƒn báº£n cÃ³ Ä‘Æ°á»£c tá»« mÃ´ hÃ¬nh chuyá»ƒn tiáº¿ng Viá»‡t thÃ nh vÄƒn báº£n.
- VÄƒn báº£n tiáº¿ng Viá»‡t sau Ä‘Ã³ thÃ´ng qua má»™t mÃ´ hÃ¬nh phiÃªn dá»‹ch sang tiáº¿ng Anh cho mÃ´ hÃ¬nh sÃ¡ng táº¡o áº£nh hiá»ƒu vÃ  táº¡o áº£nh theo yÃªu cáº§u.
- Vá»›i lá»±a chá»n há»— trá»£ báº±ng AI, vÄƒn báº£n nÃ y sáº½ Ä‘Æ°á»£c cung cáº¥p cho ChatGPT chá»‰nh sá»­a láº¡i nháº§m táº¡o ra má»™t Ä‘oáº¡n vÄƒn hay hÆ¡n giÃºp hÃ¬nh áº£nh sinh ra báº¯t máº¯t hÆ¡n.

<center><image alt ="Lá»±a chá»n vá»›i AI" src = "https://i.imgur.com/5H4efBb.png" height = 50% width = 50%/></center>

- Ráº¥t Ä‘Æ¡n giáº£n báº¡n Ä‘Ã£ cÃ³ cho mÃ¬nh má»™t bá»©c áº£nh tuyá»‡t vá»i chá»‰ tá»« giá»ng nÃ³i.

### **CÃ¡c mÃ´ hÃ¬nh pretrained Ä‘Æ°á»£c sá»­ dá»¥ng**

#### **ChatGPT (phiÃªn báº£n 3.5)**

- Dá»±a trÃªn mÃ´ hÃ¬nh ngÃ´n ngá»¯ pre-trained GPT, ChatGPT Ä‘Æ°á»£c tinh chá»‰nh láº¡i cho phÃ¹ há»£p vÃ  tá»‘i Æ°u cho viá»‡c tráº£ lá»i vÃ  sÃ¡ng táº¡o ná»™i dung há»— trá»£ ngÆ°á»i dÃ¹ng.
- ChatGPT Ä‘Æ°á»£c sá»­ dá»¥ng trong web Ä‘á»ƒ táº¡o ra nhá»¯ng Ä‘oáº¡n vÄƒn báº£n (prompt) Ä‘á»ƒ mÃ´ hÃ¬nh sÃ¡ng táº¡o áº£nh sá»­ dá»¥ng lÃ m thÃ´ng tin Ä‘á»ƒ táº¡o ra áº£nh Ä‘Ãºng vá»›i yÃªu cáº§u ngÆ°á»i dÃ¹ng.

#### **Stable Diffusion OpenJourney**

- Stable Diffusion lÃ  má»™t mÃ´ hÃ¬nh Generative AI mÃ£ nguá»“n má»Ÿ Ä‘Æ°Æ¡Ì£c phaÌt triÃªÌ‰n bÆ¡Ì‰i cÃ´ng ty Stability AI vaÌ€ ra mÄƒÌt cÃ´ng khai vaÌ€o nÄƒm 2022, cÃ³ kháº£ nÄƒng táº¡o ra báº¥t ká»³ hÃ¬nh áº£nh chi tiÃªÌt theo Ã½ muá»‘n dÆ°Ì£a trÃªn prompt vÄƒn báº£n 
- MÃ´ hÃ¬nh nÃ y dá»±a trÃªn cÃ´ng nghá»‡ Diffusion (khuáº¿ch tÃ¡n) vÃ  sá»­ dá»¥ng Latent space (khÃ´ng gian ngáº§m).

**Huáº¥n luyá»‡n**

Giáº£ sá»­ ta cÃ³ bá»©c áº£nh "chÃ³" vÃ  "mÃ¨o"
- QuÃ¡ trÃ¬nh forward diffusion thÃªm nhiá»…u vÃ o áº£nh huáº¥n luyá»‡n, dáº§n dáº§n biáº¿n nÃ³ thÃ nh áº£nh nhiá»…u khÃ´ng Ä‘áº·c trÆ°ng. CÃ¡c bá»©c áº£nh nÃ y sáº½ trá»Ÿ thÃ nh áº£nh vá»›i máº­t Ä‘á»— nhiá»…u ráº¥t cao Ä‘áº¿n ná»•i ta khÃ´ng cÃ²n nháº­n diá»‡n Ä‘Æ°á»£c áº£nh lÃ  chÃ³ hay lÃ  mÃ¨o.
- QuÃ¡ trÃ¬nh reverse diffusion sáº½ cá»‘ Ä‘áº£o ngÆ°á»£c bá»©c áº£nh nhiá»…u, hÆ°á»›ng tá»›i hÃ¬nh áº£nh mÃ¨o hoáº·c chÃ³ vÃ  táº¥t nhiÃªn khÃ´ng cÃ³ gÃ¬ á»Ÿ giá»¯a "chÃ³" vÃ  "mÃ¨o". ÄÃ³ lÃ  lÃ½ do táº¡i sao káº¿t quáº£ cÃ³ thá»ƒ lÃ  má»™t con mÃ¨o hoáº·c má»™t con chÃ³.
- Äá»ƒ Ä‘áº£o ngÆ°á»£c sá»± khuáº¿ch tÃ¡n (reverse diffusion), chÃºng ta cáº§n biáº¿t lÆ°á»£ng nhiá»…u Ä‘Æ°á»£c thÃªm vÃ o hÃ¬nh áº£nh lÃ  bao nhiÃªu. CÃ¢u tráº£ lá»i lÃ  huáº¥n luyá»‡n má»™t mÃ´ hÃ¬nh máº¡ng nÆ¡ ron Ä‘á»ƒ dá»± Ä‘oÃ¡n bao nhiÃªu nhiá»…u Ä‘Ã£ Ä‘Æ°á»£c thÃªm vÃ o. NÃ³ Ä‘Æ°á»£c gá»i lÃ  noise predictor trong stable diffusion.

**Hoáº¡t Ä‘á»™ng**

Má»™t cÃ¡ch Ä‘Æ¡n giáº£n, mÃ´ hÃ¬nh nÃ y cÃ³ cÆ¡ cháº¿ hoáº¡t Ä‘á»™ng nhÆ° hÃ¬nh bÃªn dÆ°á»›i
<center><image src = "https://i.imgur.com/67n1BX1.png" height=50% weight=50%/></center>


#### **Google Translate**

- Google Dá»‹ch (tiáº¿ng Anh lÃ  Google Translate) lÃ  má»™t cÃ´ng cá»¥ dá»‹ch thuáº­t trá»±c tuyáº¿n Ä‘a ngÃ´n ngá»¯ miá»…n phÃ­ Ä‘Æ°á»£c phÃ¡t triá»ƒn bá»Ÿi Google. 
- Google Dá»‹ch sá»­ dá»¥ng cÃ´ng cá»¥ dá»‹ch mÃ¡y mÃ´ phá»ng dÃ¢y tháº§n kinh - Google Neural Machine Translation (GNMT) - dá»‹ch "toÃ n bá»™ cÃ¢u táº¡i má»™t thá»i Ä‘iá»ƒm, chá»© khÃ´ng pháº£i tá»«ng máº£nh má»™t. NÃ³ sá»­ dá»¥ng ngá»¯ cáº£nh rá»™ng hÆ¡n nÃ y Ä‘á»ƒ giÃºp nÃ³ tÃ¬m ra báº£n dá»‹ch phÃ¹ há»£p nháº¥t, sau Ä‘Ã³ nÃ³ sáº¯p xáº¿p láº¡i vÃ  Ä‘iá»u chá»‰nh Ä‘á»ƒ giá»‘ng nhÆ° má»™t ngÆ°á»i nÃ³i vá»›i ngá»¯ phÃ¡p thÃ­ch há»£p hÆ¡n".
- Google Neural Machine Translation (GNMT) hoáº¡t Ä‘á»™ng dá»±a trÃªn má»™t máº¡ng nÆ¡-ron nhÃ¢n táº¡o lá»›n cÃ³ kháº£ nÄƒng há»c sÃ¢u. GNMT cáº£i thiá»‡n cháº¥t lÆ°á»£ng dá»‹ch báº±ng cÃ¡ch sá»­ dá»¥ng hÃ ng triá»‡u vÃ­ dá»¥, sá»­ dá»¥ng ngá»¯ cáº£nh rá»™ng hÆ¡n Ä‘á»ƒ suy ra báº£n dá»‹ch phÃ¹ há»£p nháº¥t. Káº¿t quáº£ sau Ä‘Ã³ Ä‘Æ°á»£c sáº¯p xáº¿p láº¡i vÃ  Ä‘iá»u chá»‰nh Ä‘á»ƒ tiáº¿p cáº­n ngÃ´n ngá»¯ dá»±a trÃªn ngá»¯ phÃ¡p cá»§a con ngÆ°á»i.


#### **Google Speech Recognition**

- Google Nháº­n dáº¡ng Giá»ng nÃ³i lÃ  cÃ´ng nghá»‡ do Google phÃ¡t triá»ƒn Ä‘á»ƒ chuyá»ƒn Ä‘á»•i ngÃ´n ngá»¯ nÃ³i thÃ nh vÄƒn báº£n viáº¿t vá»›i cÃ¡c cÆ¡ cháº¿ báº£o máº­t quyá»n riÃªng tÆ° ráº¥t tá»‘t.

**CÃ´ng nghá»‡ sá»­ dá»¥ng Ä‘á»ƒ huáº¥n luyá»‡n mÃ´ hÃ¬nh:**
-	*Conventional Learning:* CÃ¡c máº«u Ã¢m thanh sáº½ Ä‘Æ°á»£c thu tháº­p vÃ  lÆ°u trá»¯ trÃªn mÃ¡y chá»§ cá»§a Google. Má»™t pháº§n cá»§a cÃ¡c máº«u Ã¢m thanh nÃ y Ä‘Æ°á»£c con ngÆ°á»i chÃº thÃ­ch. Má»™t thuáº­t toÃ¡n huáº¥n luyá»‡n há»c tá»« cÃ¡c máº«u dá»¯ liá»‡u Ã¢m thanh cÃ³ chÃº thÃ­ch.
    - Trong quÃ¡ trÃ¬nh Ä‘Ã o táº¡o cÃ³ giÃ¡m sÃ¡t, cÃ¡c mÃ´ hÃ¬nh Ä‘Æ°á»£c huáº¥n luyá»‡n Ä‘á»ƒ báº¯t chÆ°á»›c chÃº thÃ­ch cá»§a con ngÆ°á»i cho cÃ¹ng má»™t Ã¢m thanh.
    - Trong Ä‘Ã o táº¡o khÃ´ng giÃ¡m sÃ¡t, chÃº thÃ­ch cá»§a mÃ¡y Ä‘Æ°á»£c sá»­ dá»¥ng thay vÃ¬ chÃº thÃ­ch cá»§a con ngÆ°á»i
-	*Federated Learning:* ÄÃ¢y lÃ  ká»¹ thuáº­t báº£o vá»‡ quyá»n riÃªng tÆ° Ä‘Æ°á»£c phÃ¡t triá»ƒn táº¡i Google Ä‘á»ƒ huáº¥n luyá»‡n cÃ¡c mÃ´ hÃ¬nh AI trá»±c tiáº¿p trÃªn Ä‘iá»‡n thoáº¡i hoáº·c thiáº¿t bá»‹ khÃ¡c cá»§a ngÆ°á»i dÃ¹ng. Vá»›i federated learning, cÃ¡c máº«u giá»ng nÃ³i sáº½ Ä‘Æ°á»£c Ä‘Ã o táº¡o mÃ  khÃ´ng gá»­i dá»¯ liá»‡u Ã¢m thanh cá»§a ngÆ°á»i dÃ¹ng Ä‘áº¿n mÃ¡y chá»§ cá»§a Google. Má»™t thuáº­t toÃ¡n huáº¥n luyá»‡n há»c tá»« dá»¯ liá»‡u Ã¢m thanh nÃ y trÃªn thiáº¿t bá»‹. Tá»« Ä‘Ã³, má»™t mÃ´ hÃ¬nh giá»ng nÃ³i má»›i Ä‘Æ°á»£c hÃ¬nh thÃ nh báº±ng cÃ¡ch káº¿t há»£p thÃ´ng tin há»c Ä‘Æ°á»£c tá»•ng há»£p tá»« táº¥t cáº£ cÃ¡c thiáº¿t bá»‹ tham gia.
-	*Ephemeral Learning:* ÄÃ¢y lÃ  má»™t ká»¹ thuáº­t báº£o vá»‡ quyá»n riÃªng tÆ° khÃ¡c Ä‘Æ°á»£c sá»­ dá»¥ng khi máº«u giá»ng nÃ³i cháº¡y trÃªn mÃ¡y chá»§ cá»§a Google. Khi há»‡ thá»‘ng cá»§a Google chuyá»ƒn Ä‘á»•i cÃ¡c máº«u Ã¢m thanh Ä‘áº§u vÃ o thÃ nh vÄƒn báº£n, cÃ¡c máº«u Ä‘Ã³ sáº½ Ä‘Æ°á»£c gá»­i tá»›i bá»™ nhá»› ngáº¯n háº¡n (RAM). Sau khi há»c thá»i gian thá»±c, cÃ¡c máº«u dá»¯ liá»‡u Ã¢m thanh nÃ y sáº½ bá»‹ xÃ³a khá»i bá»™ nhá»› ngáº¯n háº¡n trong vÃ²ng vÃ i phÃºt.


### **CÃ¡ch thá»©c hoáº¡t Ä‘á»™ng cá»§a trang web**

#### **Chá»n chá»§ Ä‘á»**

<center><image src="https://i.imgur.com/dlKuLHy.png" height=50% width=50%/></center>

- Má»—i táº­p há»£p lá»±a chá»n Ä‘áº¿n tá»« ngÆ°á»i dÃ¹ng thÃ´ng qua viá»‡c gá»i API, sáº½ Ä‘Æ°á»£c ChatGPT xÃ¢y dá»±ng thÃ nh má»™t prompt hoÃ n chá»‰nh.
- Prompt nÃ y sau khi Ä‘Æ°á»£c táº¡o ra thÃ nh cÃ´ng sáº½ Ä‘Æ°á»£c gá»­i Ä‘áº¿n mÃ´ hÃ¬nh OpenJourney thÃ´ng qua API cung cáº¥p bá»Ÿi Huggingface
- Sau má»™t thá»i gian xá»­ lÃ½, áº£nh Ä‘Æ°á»£c sÃ¡ng táº¡o sáº½ hiá»ƒn thá»‹ cho ngÆ°á»i dÃ¹ng.

#### **Giá»ng nÃ³i**

<center><image src="https://i.imgur.com/SXIqJoJ.png" width = 50% height = 50%/></center>

- Tá»« Ã¢m thanh Ä‘áº§u vÃ o nhá»› vÃ o SpeechRecognize sáº½ chuyá»ƒn thÃ nh vÄƒn báº£n tiáº¿ng Viá»‡t.
- VÄƒn báº£n nÃ y sáº½ Ä‘Æ°á»£c Google dá»‹ch phiÃªn dá»‹ch thÃ nh tiáº¿ng Anh cho mÃ´ hÃ¬nh sÃ¡ng táº¡o hÃ¬nh áº£nh sá»­ dá»¥ng.
- Táº¡i bÆ°á»›c nÃ y ngÆ°á»i dÃ¹ng cÃ³ 2 lá»±a chá»n:
    - Sá»­ dá»¥ng trá»±c tiáº¿p vÄƒn báº£n vá»«a phiÃªn dá»‹ch Ä‘á»ƒ táº¡o áº£nh.
    - Nhá» sá»± há»— trá»£ cá»§a ChatGPT cá»§a OpenAI Ä‘á»ƒ Ä‘oáº¡n vÄƒn báº£n tá»‘t hÆ¡n.
- Cuá»‘i cÃ¹ng dá»¯ liá»‡u vÄƒn báº£n (prompt) Ä‘Æ°á»£c truyá»n cho mÃ´ hÃ¬nh OpenJourney thÃ´ng qua API cung cáº¥p bá»Ÿi Huggingface Ä‘á»ƒ táº¡o ra hÃ¬nh áº£nh theo yÃªu cáº§u.

#### **VÄƒn báº£n**

<center><image src="https://i.imgur.com/RoZHc3P.png" height=50% width=50%</center>

- VÄƒn báº£n Ä‘áº§u vÃ o Ä‘Æ°á»£c thÃ´ng qua API cá»§a Google dá»‹ch, phiÃªn dá»‹ch thÃ nh tiáº¿ng Anh.
- Táº¡i bÆ°á»›c nÃ y ngÆ°á»i dÃ¹ng cÃ³ 2 lá»±a chá»n:  
    - Sá»­ dá»¥ng trá»±c tiáº¿p vÄƒn báº£n vá»«a phiÃªn dá»‹ch Ä‘á»ƒ táº¡o áº£nh.
    - Nhá» sá»± há»— trá»£ cá»§a ChatGPT cá»§a OpenAI Ä‘á»ƒ Ä‘oáº¡n vÄƒn báº£n tá»‘t hÆ¡n.
- Cuá»‘i cÃ¹ng dá»¯ liá»‡u vÄƒn báº£n (prompt) Ä‘Æ°á»£c truyá»n cho mÃ´ hÃ¬nh OpenJourney thÃ´ng qua API cung cáº¥p bá»Ÿi Huggingface Ä‘á»ƒ táº¡o ra hÃ¬nh áº£nh theo yÃªu cáº§u.
